{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0cb791a",
   "metadata": {},
   "source": [
    "데이터 전처리/시각화 3-2 이론\n",
    "\n",
    "​\n",
    "\n",
    "0. 오늘 수업의 목표\n",
    "\n",
    "수업이 끝나면 학습자는 아래를 “말로 설명”할 수 있어야 합니다.\n",
    "\n",
    "GroupBy가 뭔지: “기준으로 묶고(그룹) → 요약값(집계)을 만든다”\n",
    "\n",
    "Merge가 뭔지: “두 테이블을 키로 붙여서(조인) 정보 확장한다”\n",
    "\n",
    "문자열/시간 처리가 왜 필요한지: “분석 가능한 형태로 통일하고 파생 피처를 만든다”\n",
    "\n",
    "apply/map의 차이: “간단 치환(map) vs 행 단위 규칙(apply)”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2359729",
   "metadata": {},
   "source": [
    "# 1. 큰 그림: 원본 로그 → 리포트 테이블\n",
    "\n",
    "## 데이터 분석에서 자주 보는 3단 구조\n",
    "\n",
    "1. 원본 로그(거래/주문 단위)\n",
    "\n",
    "- 주문 1건, 결제 1건처럼 “사건 기록”이 한 행씩 쌓인 데이터\n",
    "\n",
    "- 행이 많고 값이 들쭉날쭉해서 그대로는 리포트(요약표) 만들기 어려움\n",
    "\n",
    "2. 분석용 테이블(정제/통일/파생)\n",
    "\n",
    "- 분석이 되도록 형식과 타입을 통일한 상태\n",
    "\n",
    "- 예: 날짜 형식 통일, 가격을 숫자로 변환, 결제 여부(True/False) 통일\n",
    "\n",
    "- 추가로 리포트에 필요한 파생 컬럼 생성(예: 연-월, 요일, 매출 컬럼)\n",
    "\n",
    "3. 요약 테이블(집계/피벗)\n",
    "\n",
    "- GroupBy/피벗으로 만든 최종 결과표\n",
    "\n",
    "- 보고서나 대시보드에 바로 붙여 넣을 수 있는 형태"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff12b47",
   "metadata": {},
   "source": [
    "카페 매출 데이터로 치면\n",
    "\n",
    "원본 로그 예시 컬럼\n",
    "\n",
    "date, menu, price, qty, paid, store, channel ...\n",
    "\n",
    "이 원본을 그대로 쓰면 문제가 생깁니다.\n",
    "\n",
    "\"4,500원\" 같은 문자열 때문에 합계/평균 계산이 깨지거나\n",
    "\n",
    "\"Latte\", \"latte\", \" Latte \"가 서로 다른 메뉴로 집계되어 결과가 왜곡됩니다.\n",
    "\n",
    "그래서 먼저 분석용 테이블로 바꿉니다.\n",
    "\n",
    "date → datetime\n",
    "\n",
    "price, qty → 숫자\n",
    "\n",
    "paid → True/False\n",
    "\n",
    "ym(연-월), day_name(요일), sales(매출) 같은 파생 컬럼 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facb4db6",
   "metadata": {},
   "source": [
    "최종 요약표(리포트) 예시\n",
    "\n",
    "월별 매출 추이: 이번 달 vs 지난 달 비교\n",
    "\n",
    "요일별 매출 패턴: 어떤 요일이 강한지(운영/인력 배치에 유용)\n",
    "\n",
    "메뉴 TOP / 카테고리별 매출: 잘 팔리는 메뉴/카테고리 파악(메뉴 전략)\n",
    "\n",
    "결제 성공률(또는 실패율): 오류/취소/실패 비중 점검"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fb410a",
   "metadata": {},
   "source": [
    "# 2. GroupBy(그룹화) 이론\n",
    "\n",
    "## 2-1. GroupBy란?\n",
    "\n",
    "GroupBy = “기준 컬럼으로 묶고(그룹) → 각 그룹의 요약값(집계)을 만든다” 입니다.\n",
    "\n",
    "원본 데이터가 주문 1건씩 쌓여 있을 때, 이를 리포트용 요약표로 바꾸는 가장 대표적인 방법이에요.\n",
    "\n",
    "예시(카페 매출)\n",
    "\n",
    "- 메뉴별 매출 합계: “Americano가 총 얼마 벌었나?”\n",
    "\n",
    "- 매장별 주문 수: “광교점은 주문이 몇 건인가?”\n",
    "\n",
    "- 월별 결제 성공률: “이번 달 결제 실패가 늘었나?”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd738180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 로그\n",
      "        date store       menu  sales   paid       ym\n",
      "0 2026-01-01   광교점  Americano   9000   True  2026-01\n",
      "1 2026-01-01   광교점      Latte   5000   True  2026-01\n",
      "2 2026-01-02   광교점      Latte      0  False  2026-01\n",
      "3 2026-01-03   수원점  Americano   4500   True  2026-01\n",
      "4 2026-01-03   수원점      Mocha      0  False  2026-01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) 주문(원본 로그) 데이터: \"주문 1건 = 행 1개\"\n",
    "df = pd.DataFrame([\n",
    "    {\"date\": \"2026-01-01\", \"store\": \"광교점\", \"menu\": \"Americano\", \"sales\": 9000, \"paid\": True},\n",
    "    {\"date\": \"2026-01-01\", \"store\": \"광교점\", \"menu\": \"Latte\",     \"sales\": 5000, \"paid\": True},\n",
    "    {\"date\": \"2026-01-02\", \"store\": \"광교점\", \"menu\": \"Latte\",     \"sales\": 0,    \"paid\": False},\n",
    "    {\"date\": \"2026-01-03\", \"store\": \"수원점\", \"menu\": \"Americano\", \"sales\": 4500, \"paid\": True},\n",
    "    {\"date\": \"2026-01-03\", \"store\": \"수원점\", \"menu\": \"Mocha\",     \"sales\": 0,    \"paid\": False},\n",
    "])\n",
    "\n",
    "# 날짜를 datetime으로 바꾸고, 월(ym) 컬럼 생성 (월별 그룹화용)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"ym\"] = df[\"date\"].dt.to_period(\"M\").astype(str) # .dt = datetype\n",
    "\n",
    "print(\"원본 로그\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9b773c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date     datetime64[ns]\n",
       "store            object\n",
       "menu             object\n",
       "sales             int64\n",
       "paid               bool\n",
       "ym               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71787ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "메뉴별 매출 합계\n",
      "        menu  sales\n",
      "0  Americano  13500\n",
      "1      Latte   5000\n",
      "2      Mocha      0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2) 메뉴별 매출 합계: \"Americano가 총 얼마 벌었나?\"\n",
    "menu_sales = df.groupby(\"menu\")[\"sales\"].sum().reset_index()\n",
    "print(\"\\n메뉴별 매출 합계\")\n",
    "print(menu_sales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d87c063d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(menu_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e073fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "매장별 주문 수\n",
      "  store  orders\n",
      "0   광교점       3\n",
      "1   수원점       2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3) 매장별 주문 수: \"광교점은 주문이 몇 건인가?\"\n",
    "store_orders = df.groupby(\"store\")[\"menu\"].count().reset_index(name=\"orders\")\n",
    "print(\"\\n매장별 주문 수\")\n",
    "print(store_orders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c55ea9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "월별 결제 성공률\n",
      "        ym  paid_rate\n",
      "0  2026-01        0.6\n"
     ]
    }
   ],
   "source": [
    "# 4) 월별 결제 성공률: \"이번 달 결제 실패가 늘었나?\"\n",
    "# paid가 True/False이면 mean()이 성공률(비율)처럼 동작합니다.\n",
    "monthly_paid_rate = df.groupby(\"ym\")[\"paid\"].mean().reset_index(name=\"paid_rate\")\n",
    "print(\"\\n월별 결제 성공률\")\n",
    "print(monthly_paid_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d64030e",
   "metadata": {},
   "source": [
    "2-2. 왜 GroupBy가 필요한가?\n",
    "\n",
    "원본 로그는 대부분 “행 단위 사건” 이라서, 한 줄을 봐서는 흐름이 안 보입니다.\n",
    "\n",
    "주문 1건을 봐서는 “이번 달 매출이 좋은지” 판단 불가\n",
    "\n",
    "수백~수천 건을 “사람 눈”으로 봐서는 패턴을 찾기 어려움\n",
    "\n",
    "그래서 GroupBy로 요약 단위를 바꿉니다.\n",
    "\n",
    "주문 단위 → 메뉴 단위 / 매장 단위 / 월 단위\n",
    "\n",
    "이렇게 바꾸면 “비교·추세·순위”가 가능해지고, 리포트가 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "701b45b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 원본 로그(주문 1건 단위):\n",
      "        date store       menu  sales       ym\n",
      "0 2026-01-01   광교점  Americano   9000  2026-01\n",
      "1 2026-01-01   광교점      Latte   5000  2026-01\n",
      "2 2026-01-02   광교점      Latte   5000  2026-01\n",
      "3 2026-01-03   수원점  Americano   4500  2026-01\n",
      "4 2026-01-03   수원점      Mocha   5500  2026-01\n",
      "\n",
      " GroupBy 결과(메뉴 단위) = 메뉴별 매출 합계:\n",
      "        menu  total_sales\n",
      "0  Americano        13500\n",
      "1      Latte        10000\n",
      "2      Mocha         5500\n",
      "\n",
      " GroupBy 결과(매장 단위) = 매장별 매출 합계:\n",
      "  store  total_sales\n",
      "0   광교점        19000\n",
      "1   수원점        10000\n",
      "\n",
      " GroupBy 결과(월 단위) = 월별 매출 합계:\n",
      "        ym  total_sales\n",
      "0  2026-01        29000\n",
      "\n",
      " 메뉴 매출 TOP(정렬로 순위 확인):\n",
      "        menu  total_sales\n",
      "0  Americano        13500\n",
      "1      Latte        10000\n",
      "2      Mocha         5500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 원본 로그(주문 1건 = 1행)\n",
    "df = pd.DataFrame([\n",
    "    {\"date\": \"2026-01-01\", \"store\": \"광교점\", \"menu\": \"Americano\", \"sales\": 9000},\n",
    "    {\"date\": \"2026-01-01\", \"store\": \"광교점\", \"menu\": \"Latte\",     \"sales\": 5000},\n",
    "    {\"date\": \"2026-01-02\", \"store\": \"광교점\", \"menu\": \"Latte\",     \"sales\": 5000},\n",
    "    {\"date\": \"2026-01-03\", \"store\": \"수원점\", \"menu\": \"Americano\", \"sales\": 4500},\n",
    "    {\"date\": \"2026-01-03\", \"store\": \"수원점\", \"menu\": \"Mocha\",     \"sales\": 5500},\n",
    "])\n",
    "\n",
    "# 날짜 -> datetime, 월(ym) 컬럼 생성\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"ym\"] = df[\"date\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "print(\" 원본 로그(주문 1건 단위):\")\n",
    "print(df)\n",
    "\n",
    "# 1) 주문 단위 -> 메뉴 단위 (메뉴별 매출 합계)\n",
    "menu_report = df.groupby(\"menu\")[\"sales\"].sum().reset_index(name=\"total_sales\")\n",
    "print(\"\\n GroupBy 결과(메뉴 단위) = 메뉴별 매출 합계:\")\n",
    "print(menu_report)\n",
    "\n",
    "# 2) 주문 단위 -> 매장 단위 (매장별 매출 합계)\n",
    "store_report = df.groupby(\"store\")[\"sales\"].sum().reset_index(name=\"total_sales\")\n",
    "print(\"\\n GroupBy 결과(매장 단위) = 매장별 매출 합계:\")\n",
    "print(store_report)\n",
    "\n",
    "# 3) 주문 단위 -> 월 단위 (월별 매출 합계)\n",
    "month_report = df.groupby(\"ym\")[\"sales\"].sum().reset_index(name=\"total_sales\")\n",
    "print(\"\\n GroupBy 결과(월 단위) = 월별 매출 합계:\")\n",
    "print(month_report)\n",
    "\n",
    "# (추가) 순위/비교가 쉬워짐: 메뉴 매출 TOP 정렬\n",
    "top_menu = menu_report.sort_values(\"total_sales\", ascending=False)\n",
    "print(\"\\n 메뉴 매출 TOP(정렬로 순위 확인):\")\n",
    "print(top_menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bf1bd0",
   "metadata": {},
   "source": [
    "2-3. 집계 함수(aggregation) 핵심 5종\n",
    "\n",
    "GroupBy의 결과를 만들 때는 “어떤 요약값을 뽑을지”가 중요합니다.\n",
    "\n",
    "- sum: 총합\n",
    "\n",
    "예: 총매출, 총수량\n",
    "\n",
    "- mean: 평균\n",
    "\n",
    "예: 평균 객단가, 평균 수량, 성공률(비율)\n",
    "\n",
    "- count: 개수\n",
    "\n",
    "예: 주문 건수(행 개수)\n",
    "\n",
    "- nunique: 고유값 개수 -> Disticnt\n",
    "\n",
    "예: 고유 고객 수, 고유 메뉴 수\n",
    "\n",
    "- min / max: 최소/최대\n",
    "\n",
    "예: 최소/최대 매출일, 최대 주문수량\n",
    "\n",
    "초보자 포인트(중요)\n",
    "\n",
    "paid가 True/False일 때, mean(paid)는 성공률처럼 해석될 수 있습니다.\n",
    "\n",
    "(True는 1, False는 0처럼 동작하기 때문)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a449c32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터\n",
      "  store       menu  qty  sales   paid\n",
      "0   광교점  Americano    2   9000   True\n",
      "1   광교점      Latte    1   5000   True\n",
      "2   광교점      Latte    2      0  False\n",
      "3   수원점  Americano    1   4500   True\n",
      "4   수원점      Mocha    1      0  False\n",
      "\n",
      "매장별 요약(집계 5종 + paid_rate)\n",
      "  store  total_sales    avg_sales  orders  unique_menus  min_qty  max_qty  \\\n",
      "0   광교점        14000  4666.666667       3             2        1        2   \n",
      "1   수원점         4500  2250.000000       2             2        1        1   \n",
      "\n",
      "   paid_rate  \n",
      "0   0.666667  \n",
      "1   0.500000  \n",
      "\n",
      "paid 컬럼 확인(참고): True/False 평균 = 성공률\n",
      "store\n",
      "광교점    [True, True, False]\n",
      "수원점          [True, False]\n",
      "Name: paid, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 예시 데이터(주문 1건 = 1행)\n",
    "df = pd.DataFrame([\n",
    "    {\"store\": \"광교점\", \"menu\": \"Americano\", \"qty\": 2, \"sales\": 9000, \"paid\": True},\n",
    "    {\"store\": \"광교점\", \"menu\": \"Latte\",     \"qty\": 1, \"sales\": 5000, \"paid\": True},\n",
    "    {\"store\": \"광교점\", \"menu\": \"Latte\",     \"qty\": 2, \"sales\": 0,    \"paid\": False},\n",
    "    {\"store\": \"수원점\", \"menu\": \"Americano\", \"qty\": 1, \"sales\": 4500, \"paid\": True},\n",
    "    {\"store\": \"수원점\", \"menu\": \"Mocha\",     \"qty\": 1, \"sales\": 0,    \"paid\": False},\n",
    "])\n",
    "\n",
    "print(\"원본 데이터\")\n",
    "print(df)\n",
    "\n",
    "# GroupBy + 집계 함수 5종 (매장별로 요약표 만들기)\n",
    "summary = df.groupby(\"store\").agg(\n",
    "    total_sales=(\"sales\", \"sum\"),     # sum: 총합\n",
    "    avg_sales=(\"sales\", \"mean\"),      # mean: 평균\n",
    "    orders=(\"menu\", \"count\"),         # count: 개수(행 개수)\n",
    "    unique_menus=(\"menu\", \"nunique\"), # nunique: 고유값 개수\n",
    "    min_qty=(\"qty\", \"min\"),           # min: 최소\n",
    "    max_qty=(\"qty\", \"max\"),           # max: 최대\n",
    "    paid_rate=(\"paid\", \"mean\"),       # mean(True/False) = 성공률(비율)\n",
    ").reset_index()\n",
    "\n",
    "print(\"\\n매장별 요약(집계 5종 + paid_rate)\")\n",
    "print(summary)\n",
    "\n",
    "# 참고: paid_rate가 왜 비율이 되는지 확인 (True=1, False=0처럼 동작)\n",
    "print(\"\\npaid 컬럼 확인(참고): True/False 평균 = 성공률\")\n",
    "print(df.groupby(\"store\")[\"paid\"].apply(list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e13b5e",
   "metadata": {},
   "source": [
    "2-4. 단일 기준 vs 다중 기준 (리포트가 달라짐)\n",
    "\n",
    "1. 단일 기준 그룹화\n",
    "\n",
    "기준: menu 하나만\n",
    "\n",
    "결과: “메뉴별 매출 TOP”처럼 단순하고 직관적인 표\n",
    "\n",
    "2. 다중 기준 그룹화\n",
    "\n",
    "기준: ym(월) + day_name(요일)처럼 2개 이상\n",
    "\n",
    "결과: “월별-요일별 매출 패턴” 같은 리포트형 분석이 가능\n",
    "\n",
    "예: “1월은 월요일이 강하고, 금요일은 약하다” 같은 패턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef326175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 로그\n",
      "        date       menu  sales       ym   day_name\n",
      "0 2026-01-01  Americano   9000  2026-01   Thursday\n",
      "1 2026-01-02      Latte   5000  2026-01     Friday\n",
      "2 2026-01-03      Latte   5000  2026-01   Saturday\n",
      "3 2026-01-06  Americano   4500  2026-01    Tuesday\n",
      "4 2026-01-07      Mocha   5500  2026-01  Wednesday\n",
      "\n",
      " 단일 기준(menu) 그룹화: 메뉴별 매출 TOP\n",
      "        menu  total_sales\n",
      "0  Americano        13500\n",
      "1      Latte        10000\n",
      "2      Mocha         5500\n",
      "\n",
      " 다중 기준(ym + day_name) 그룹화: 월별-요일별 매출\n",
      "        ym   day_name  total_sales\n",
      "2  2026-01   Thursday         9000\n",
      "4  2026-01  Wednesday         5500\n",
      "0  2026-01     Friday         5000\n",
      "1  2026-01   Saturday         5000\n",
      "3  2026-01    Tuesday         4500\n",
      "\n",
      " 피벗(월 x 요일) = 매출 패턴 표\n",
      "day_name  Friday  Saturday  Thursday  Tuesday  Wednesday\n",
      "ym                                                      \n",
      "2026-01     5000      5000      9000     4500       5500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 예시 데이터(주문 1건 = 1행)\n",
    "df = pd.DataFrame([\n",
    "    {\"date\": \"2026-01-01\", \"menu\": \"Americano\", \"sales\": 9000},\n",
    "    {\"date\": \"2026-01-02\", \"menu\": \"Latte\",     \"sales\": 5000},\n",
    "    {\"date\": \"2026-01-03\", \"menu\": \"Latte\",     \"sales\": 5000},\n",
    "    {\"date\": \"2026-01-06\", \"menu\": \"Americano\", \"sales\": 4500},\n",
    "    {\"date\": \"2026-01-07\", \"menu\": \"Mocha\",     \"sales\": 5500},\n",
    "])\n",
    "\n",
    "# 날짜 처리 + 파생 컬럼(월/요일) 만들기\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"ym\"] = df[\"date\"].dt.to_period(\"M\").astype(str)     # \"2026-01\"\n",
    "df[\"day_name\"] = df[\"date\"].dt.day_name()               # Monday, Tuesday...\n",
    "\n",
    "print(\"원본 로그\")\n",
    "print(df)\n",
    "\n",
    "# 1) 단일 기준 그룹화: menu 하나만\n",
    "menu_report = (\n",
    "    df.groupby(\"menu\")[\"sales\"].sum()\n",
    "      .reset_index(name=\"total_sales\")\n",
    "      .sort_values(\"total_sales\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"\\n 단일 기준(menu) 그룹화: 메뉴별 매출 TOP\")\n",
    "print(menu_report)\n",
    "\n",
    "# 2) 다중 기준 그룹화: ym(월) + day_name(요일)\n",
    "ym_day_report = (\n",
    "    df.groupby([\"ym\", \"day_name\"])[\"sales\"].sum()\n",
    "      .reset_index(name=\"total_sales\")\n",
    "      .sort_values([\"ym\", \"total_sales\"], ascending=[True, False])\n",
    ")\n",
    "\n",
    "print(\"\\n 다중 기준(ym + day_name) 그룹화: 월별-요일별 매출\")\n",
    "print(ym_day_report)\n",
    "\n",
    "# (선택) 리포트처럼 보이게 피벗 형태로 변환\n",
    "pivot = (\n",
    "    ym_day_report.pivot(index=\"ym\", columns=\"day_name\", values=\"total_sales\")\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "print(\"\\n 피벗(월 x 요일) = 매출 패턴 표\")\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fce0df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1) 원본(세로형, Long format) — “주문/기록이 행으로 쌓이는 형태”\n",
    "# +---------+-----------+-------+\n",
    "# | Month   | Menu      | Sales |\n",
    "# +---------+-----------+-------+\n",
    "# | 2025-01 | Latte     |   1   |\n",
    "# | 2025-01 | Americano |   2   |\n",
    "# | 2025-01 | Mocha     |   3   |\n",
    "# | 2025-02 | Latte     |   2   |\n",
    "# | 2025-02 | Americano |   3   |\n",
    "# | 2025-02 | Mocha     |   4   |\n",
    "# +---------+-----------+-------+\n",
    "# \n",
    "# # 2) 피벗 결과(가로형, Wide format) — “행/열로 보기 좋게 펼친 형태”\n",
    "# +-----------+---------+---------+\n",
    "# | Menu\\Month| 2025-01 | 2025-02 |\n",
    "# +-----------+---------+---------+\n",
    "# | Latte     |   1     |   2     |\n",
    "# | Americano |   2     |   3     |\n",
    "# | Mocha     |   3     |   4     |\n",
    "# +-----------+---------+---------+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3019ac24",
   "metadata": {},
   "source": [
    "## 2-5. agg()가 중요한 이유\n",
    "\n",
    "초보자들이 흔히 “sum만” 만들고 끝내는데, 실무 리포트는 보통 한 표에 여러 지표가 필요합니다.\n",
    "\n",
    "예)\n",
    "\n",
    "total_sales(매출 합계)\n",
    "\n",
    "orders(주문 수)\n",
    "\n",
    "paid_rate(결제 성공률)\n",
    "\n",
    "이런 걸 한 번에 뽑아주는 것이 agg()의 강점입니다.\n",
    "\n",
    "즉, agg()는 리포트형 요약테이블 제작에 최적이에요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0009a0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 로그\n",
      "  store       menu  sales   paid\n",
      "0   광교점  Americano   9000   True\n",
      "1   광교점      Latte   5000   True\n",
      "2   광교점      Latte      0  False\n",
      "3   수원점  Americano   4500   True\n",
      "4   수원점      Mocha      0  False\n",
      "\n",
      " 매장별 리포트 요약표(agg로 한 번에 생성)\n",
      "  store  total_sales  orders  paid_rate\n",
      "0   광교점        14000       3   0.666667\n",
      "1   수원점         4500       2   0.500000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 예시 데이터(주문 1건 = 1행)\n",
    "df = pd.DataFrame([\n",
    "    {\"store\": \"광교점\", \"menu\": \"Americano\", \"sales\": 9000, \"paid\": True},\n",
    "    {\"store\": \"광교점\", \"menu\": \"Latte\",     \"sales\": 5000, \"paid\": True},\n",
    "    {\"store\": \"광교점\", \"menu\": \"Latte\",     \"sales\": 0,    \"paid\": False},\n",
    "    {\"store\": \"수원점\", \"menu\": \"Americano\", \"sales\": 4500, \"paid\": True},\n",
    "    {\"store\": \"수원점\", \"menu\": \"Mocha\",     \"sales\": 0,    \"paid\": False},\n",
    "])\n",
    "\n",
    "print(\"원본 로그\")\n",
    "print(df)\n",
    "\n",
    "# 실무 리포트용: agg()로 여러 지표를 한 번에 만들기 (매장별 요약표)\n",
    "report = df.groupby(\"store\").agg(\n",
    "    total_sales=(\"sales\", \"sum\"),   # 매출 합계\n",
    "    orders=(\"menu\", \"count\"),       # 주문 수(행 개수)\n",
    "    paid_rate=(\"paid\", \"mean\"),     # 결제 성공률(True/False 평균)\n",
    ").reset_index()\n",
    "\n",
    "print(\"\\n 매장별 리포트 요약표(agg로 한 번에 생성)\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd6b7ae",
   "metadata": {},
   "source": [
    "2-6. MultiIndex가 뭐고 왜 불편한가?\n",
    "\n",
    "다중 기준 GroupBy를 하면 결과가 종종 MultiIndex(계층 인덱스) 로 나옵니다.\n",
    "\n",
    "장점: “계층 구조”를 표현할 수 있음\n",
    "\n",
    "단점(초보자 체감):\n",
    "\n",
    "표처럼 다루기가 어렵고\n",
    "\n",
    "merge/pivot/저장(csv) 같은 후처리에 불편함\n",
    "\n",
    "그래서 실무에서는 보통\n",
    "\n",
    "reset_index()로 인덱스를 컬럼으로 내려서\n",
    "\n",
    "다시 “일반적인 표 형태”로 만들어 씁니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d369843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 로그\n",
      "        date store       menu  sales       ym\n",
      "0 2026-01-01   광교점  Americano   9000  2026-01\n",
      "1 2026-01-01   광교점      Latte   5000  2026-01\n",
      "2 2026-01-02   광교점      Latte   5000  2026-01\n",
      "3 2026-01-03   수원점  Americano   4500  2026-01\n",
      "\n",
      " 다중 기준 GroupBy 결과(Series, MultiIndex):\n",
      "ym       store\n",
      "2026-01  광교점      19000\n",
      "         수원점       4500\n",
      "Name: sales, dtype: int64\n",
      "\n",
      "인덱스 형태 확인: <class 'pandas.core.indexes.multi.MultiIndex'>\n",
      "\n",
      " reset_index() 후(일반적인 표 형태):\n",
      "        ym store  total_sales\n",
      "0  2026-01   광교점        19000\n",
      "1  2026-01   수원점         4500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 예시 데이터\n",
    "df = pd.DataFrame([\n",
    "    {\"date\": \"2026-01-01\", \"store\": \"광교점\", \"menu\": \"Americano\", \"sales\": 9000},\n",
    "    {\"date\": \"2026-01-01\", \"store\": \"광교점\", \"menu\": \"Latte\",     \"sales\": 5000},\n",
    "    {\"date\": \"2026-01-02\", \"store\": \"광교점\", \"menu\": \"Latte\",     \"sales\": 5000},\n",
    "    {\"date\": \"2026-01-03\", \"store\": \"수원점\", \"menu\": \"Americano\", \"sales\": 4500},\n",
    "])\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"ym\"] = df[\"date\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "print(\"원본 로그\")\n",
    "print(df)\n",
    "\n",
    "# 다중 기준 GroupBy → 결과가 MultiIndex로 나올 수 있음(계층 인덱스)\n",
    "multi = df.groupby([\"ym\", \"store\"])[\"sales\"].sum()\n",
    "print(\"\\n 다중 기준 GroupBy 결과(Series, MultiIndex):\")\n",
    "print(multi)\n",
    "print(\"\\n인덱스 형태 확인:\", type(multi.index))\n",
    "\n",
    "# 실무에서 자주 하는 처리: reset_index()로 '표 형태'로 바꾸기\n",
    "flat = multi.reset_index(name=\"total_sales\")\n",
    "print(\"\\n reset_index() 후(일반적인 표 형태):\")\n",
    "print(flat)\n",
    "\n",
    "# (참고) 이렇게 표가 되면 저장/merge/pivot이 쉬워짐\n",
    "# flat.to_csv(\"summary.csv\", index=False)  # 저장도 쉬움"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056efefa",
   "metadata": {},
   "source": [
    "3. 피벗(표 형태 변환) 이론: “리포트용 표 만들기” \n",
    "\n",
    "3-1. 피벗이 필요한 순간\n",
    "\n",
    "피벗은 한마디로 **“리포트에서 보기 좋은 표 모양으로 바꾸는 작업”**입니다.\n",
    "\n",
    "원본 로그는 보통 “주문 1건 = 1행”이라 아래처럼 생겼죠.\n",
    "\n",
    "(원본) date, menu, store, sales ... 형태\n",
    "\n",
    "이 상태에서는 “월별·요일별 패턴”을 한눈에 보기 어렵습니다.\n",
    "\n",
    "하지만 보고서(리포트) 표는 보통 이렇게 생깁니다.\n",
    "\n",
    "행(Row): 월(예: 2026-01, 2026-02 …)\n",
    "\n",
    "열(Column): 요일(예: Mon, Tue …)\n",
    "\n",
    "값(Value): 매출(합계)\n",
    "\n",
    "이렇게 만들면 무엇이 좋아지냐면,\n",
    "\n",
    "“어느 요일이 강한지”가 한눈에 보이고\n",
    "\n",
    "월별로 요일 패턴이 바뀌는지도 바로 비교가 됩니다.\n",
    "\n",
    "중요 포인트는:\n",
    "\n",
    "이런 “월 × 요일” 표는 원본 로그에서 바로 나오지 않고,\n",
    "\n",
    "먼저 **GroupBy로 요약(월+요일별 매출 합계)**을 만든 다음,\n",
    "\n",
    "그 결과를 피벗으로 표 모양을 바꿔서 완성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bcd8242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 원본 로그(주문 단위)\n",
      "        date       ym       day store       menu  sales\n",
      "0 2026-01-01  2026-01  Thursday   광교점  Americano   9000\n",
      "1 2026-01-02  2026-01    Friday   광교점      Latte   5000\n",
      "2 2026-01-03  2026-01  Saturday   수원점      Latte   5000\n",
      "3 2026-01-06  2026-01   Tuesday   광교점  Americano   4500\n",
      "4 2026-02-03  2026-02   Tuesday   수원점      Mocha   5500\n",
      "\n",
      " GroupBy 요약(월+요일별 매출 합계)\n",
      "        ym       day  total_sales\n",
      "0  2026-01    Friday         5000\n",
      "1  2026-01  Saturday         5000\n",
      "2  2026-01  Thursday         9000\n",
      "3  2026-01   Tuesday         4500\n",
      "4  2026-02   Tuesday         5500\n",
      "\n",
      " 피벗 리포트(월 x 요일 매출 표)\n",
      "day      Friday  Saturday  Thursday  Tuesday\n",
      "ym                                          \n",
      "2026-01  5000.0    5000.0    9000.0   4500.0\n",
      "2026-02     0.0       0.0       0.0   5500.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) 원본 로그(주문 1건 = 1행)\n",
    "df = pd.DataFrame([\n",
    "    {\"date\": \"2026-01-01\", \"menu\": \"Americano\", \"store\": \"광교점\", \"sales\": 9000},\n",
    "    {\"date\": \"2026-01-02\", \"menu\": \"Latte\",     \"store\": \"광교점\", \"sales\": 5000},\n",
    "    {\"date\": \"2026-01-03\", \"menu\": \"Latte\",     \"store\": \"수원점\", \"sales\": 5000},\n",
    "    {\"date\": \"2026-01-06\", \"menu\": \"Americano\", \"store\": \"광교점\", \"sales\": 4500},\n",
    "    {\"date\": \"2026-02-03\", \"menu\": \"Mocha\",     \"store\": \"수원점\", \"sales\": 5500},\n",
    "])\n",
    "\n",
    "# 2) 날짜 처리 + 파생 컬럼(월/요일) 만들기\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"ym\"] = df[\"date\"].dt.to_period(\"M\").astype(str)   # 예: \"2026-01\"\n",
    "df[\"day\"] = df[\"date\"].dt.day_name()                  # 예: \"Monday\"\n",
    "\n",
    "print(\" 원본 로그(주문 단위)\")\n",
    "print(df[[\"date\", \"ym\", \"day\", \"store\", \"menu\", \"sales\"]])\n",
    "\n",
    "# 3) (핵심) 월+요일별 매출 합계로 먼저 요약(GroupBy)\n",
    "summary = (\n",
    "    df.groupby([\"ym\", \"day\"])[\"sales\"].sum()\n",
    "      .reset_index(name=\"total_sales\")\n",
    ")\n",
    "\n",
    "print(\"\\n GroupBy 요약(월+요일별 매출 합계)\")\n",
    "print(summary)\n",
    "\n",
    "# 4) (핵심) 피벗으로 '월 x 요일' 리포트 표 만들기\n",
    "report = (\n",
    "    summary.pivot(index=\"ym\", columns=\"day\", values=\"total_sales\")\n",
    "    .fillna(0)  # 데이터 없는 칸은 0으로\n",
    ")\n",
    "\n",
    "print(\"\\n 피벗 리포트(월 x 요일 매출 표)\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e57be22",
   "metadata": {},
   "source": [
    "3-2. “긴 형태(long) → 넓은 형태(wide)” 감각 잡기\n",
    "\n",
    "피벗을 이해할 때 가장 쉬운 관점은 이것입니다.\n",
    "\n",
    "긴 형태(long): 행이 길게 늘어져 있는 형태\n",
    "\n",
    "예: 2026-01, Mon, 120000\n",
    "\n",
    "2026-01, Tue, 90000\n",
    "\n",
    "2026-02, Mon, 150000 …\n",
    "\n",
    "특징: “데이터 분석엔 편하지만”, 사람이 보기엔 패턴이 잘 안 보임\n",
    "\n",
    "넓은 형태(wide): 열이 펼쳐져서 표처럼 보이는 형태\n",
    "\n",
    "예:\n",
    "\n",
    "행: 2026-01 / 2026-02\n",
    "\n",
    "열: Mon, Tue, Wed…\n",
    "\n",
    "값: 매출\n",
    "\n",
    "특징: 보고서/대시보드에 바로 붙이기 좋음\n",
    "\n",
    "초보자에게는 이렇게 말하면 직관적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9485a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 긴 형태(long) 데이터\n",
      "        ym  day   sales\n",
      "0  2026-01  Mon  120000\n",
      "1  2026-01  Tue   90000\n",
      "2  2026-02  Mon  150000\n",
      "3  2026-02  Tue   80000\n",
      "\n",
      " 넓은 형태(wide) 데이터 (월 x 요일 표)\n",
      "day         Mon    Tue\n",
      "ym                    \n",
      "2026-01  120000  90000\n",
      "2026-02  150000  80000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) 긴 형태(long) 데이터: \"요일\"이 행에 들어있는 형태\n",
    "long_df = pd.DataFrame([\n",
    "    {\"ym\": \"2026-01\", \"day\": \"Mon\", \"sales\": 120000},\n",
    "    {\"ym\": \"2026-01\", \"day\": \"Tue\", \"sales\":  90000},\n",
    "    {\"ym\": \"2026-02\", \"day\": \"Mon\", \"sales\": 150000},\n",
    "    {\"ym\": \"2026-02\", \"day\": \"Tue\", \"sales\":  80000},\n",
    "])\n",
    "\n",
    "print(\" 긴 형태(long) 데이터\")\n",
    "print(long_df)\n",
    "\n",
    "#  2) 넓은 형태(wide)로 변환: 요일을 '열'로 펼치기(피벗)\n",
    "wide_df = long_df.pivot(index=\"ym\", columns=\"day\", values=\"sales\").fillna(0)\n",
    "\n",
    "print(\"\\n 넓은 형태(wide) 데이터 (월 x 요일 표)\")\n",
    "print(wide_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfd8c4b",
   "metadata": {},
   "source": [
    "3-3. pivot vs unstack은 뭐가 다른가?\n",
    "\n",
    "둘 다 결과는 비슷하게 “표 형태(wide)”를 만들 수 있어요.\n",
    "\n",
    "pivot\n",
    "\n",
    "“행/열/값을 지정해서 피벗 표를 만든다”\n",
    "\n",
    "초보자에게 가장 추천(가독성이 좋음)\n",
    "\n",
    "unstack\n",
    "\n",
    "GroupBy 결과가 MultiIndex일 때\n",
    "\n",
    "“한 인덱스 레벨을 열로 펼친다” 느낌\n",
    "\n",
    "pivot보다 조금 더 ‘GroupBy 결과를 다루는’ 방식에 가깝습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90baa6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본(long 형태)\n",
      "        ym  day  sales\n",
      "0  2026-01  Mon    100\n",
      "1  2026-01  Mon     50\n",
      "2  2026-01  Tue     80\n",
      "3  2026-02  Mon    120\n",
      "\n",
      "GroupBy로 먼저 요약(중복 조합 해결)\n",
      "        ym  day  total_sales\n",
      "0  2026-01  Mon          150\n",
      "1  2026-01  Tue           80\n",
      "2  2026-02  Mon          120\n",
      "\n",
      "pivot 결과\n",
      "day        Mon   Tue\n",
      "ym                  \n",
      "2026-01  150.0  80.0\n",
      "2026-02  120.0   NaN\n",
      "\n",
      "unstack 결과\n",
      "day        Mon   Tue\n",
      "ym                  \n",
      "2026-01  150.0  80.0\n",
      "2026-02  120.0   NaN\n",
      "\n",
      "NaN을 0으로 채운 리포트 표\n",
      "day        Mon   Tue\n",
      "ym                  \n",
      "2026-01  150.0  80.0\n",
      "2026-02  120.0   0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 예시 데이터(일부 조합이 반복되도록 일부러 2행 넣음: 2026-01 + Mon)\n",
    "df = pd.DataFrame([\n",
    "    {\"ym\": \"2026-01\", \"day\": \"Mon\", \"sales\": 100},\n",
    "    {\"ym\": \"2026-01\", \"day\": \"Mon\", \"sales\": 50},   # 같은 조합이 2개라서 pivot이 바로 안 됨\n",
    "    {\"ym\": \"2026-01\", \"day\": \"Tue\", \"sales\": 80},\n",
    "    {\"ym\": \"2026-02\", \"day\": \"Mon\", \"sales\": 120},\n",
    "    # 2026-02의 Tue가 없어서 피벗 후 NaN이 생길 수 있음\n",
    "])\n",
    "\n",
    "print(\"원본(long 형태)\")\n",
    "print(df)\n",
    "\n",
    "# 실수 포인트 1) 같은 ym+day 조합이 여러 행이면 pivot이 바로 안 됨\n",
    "# 해결: GroupBy로 먼저 1개 값(합계/평균 등)으로 요약\n",
    "summary = df.groupby([\"ym\", \"day\"])[\"sales\"].sum().reset_index(name=\"total_sales\")\n",
    "\n",
    "print(\"\\nGroupBy로 먼저 요약(중복 조합 해결)\")\n",
    "print(summary)\n",
    "\n",
    "# 1) pivot 방식: 행/열/값을 지정해서 표 만들기\n",
    "pivot_table = summary.pivot(index=\"ym\", columns=\"day\", values=\"total_sales\")\n",
    "print(\"\\npivot 결과\")\n",
    "print(pivot_table)\n",
    "\n",
    "# 2) unstack 방식: GroupBy 결과(MultiIndex)를 열로 펼치기\n",
    "multi = df.groupby([\"ym\", \"day\"])[\"sales\"].sum()  # MultiIndex Series\n",
    "unstack_table = multi.unstack()\n",
    "print(\"\\nunstack 결과\")\n",
    "print(unstack_table)\n",
    "\n",
    "# 실수 포인트 2) 어떤 조합이 없으면 NaN이 생김\n",
    "# 리포트에서는 보통 0으로 채움\n",
    "pivot_filled = pivot_table.fillna(0)\n",
    "print(\"\\nNaN을 0으로 채운 리포트 표\")\n",
    "print(pivot_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a520cd5",
   "metadata": {},
   "source": [
    "3-4. 피벗에서 자주 만나는 실수 포인트 2개 (확장 + 간단 예제코드)\n",
    "\n",
    "1) 값이 여러 개라서 피벗이 안 되는 경우\n",
    "\n",
    "피벗은 기본적으로 “한 칸(ym + day 조합) = 값 1개”여야 합니다.\n",
    "\n",
    "그런데 원본 로그는 보통 주문이 여러 건이라 같은 월(ym) + 요일(day) 조합이 여러 번 등장합니다.\n",
    "\n",
    "예)\n",
    "\n",
    "2026-01 + Mon 주문이 3건이면\n",
    "\n",
    "피벗에서 “2026-01 행의 Mon 열”에 값이 3개가 들어가려 해서 충돌이 납니다.\n",
    "\n",
    "그래서 실무에서는 보통 이렇게 합니다.\n",
    "\n",
    "1단계: GroupBy로 먼저 요약(sum/mean 등)해서 “칸당 값 1개”로 만들기\n",
    "\n",
    "2단계: pivot으로 표 모양 만들기\n",
    "\n",
    "간단 예제코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2c8b434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ym  day  total_sales\n",
      "0  2026-01  Mon          150\n",
      "1  2026-01  Tue           80\n",
      "2  2026-02  Mon          120\n",
      "day        Mon   Tue\n",
      "ym                  \n",
      "2026-01  150.0  80.0\n",
      "2026-02  120.0   NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {\"ym\": \"2026-01\", \"day\": \"Mon\", \"sales\": 100},\n",
    "    {\"ym\": \"2026-01\", \"day\": \"Mon\", \"sales\": 50},   # 같은 조합이 반복\n",
    "    {\"ym\": \"2026-01\", \"day\": \"Tue\", \"sales\": 80},\n",
    "    {\"ym\": \"2026-02\", \"day\": \"Mon\", \"sales\": 120},\n",
    "])\n",
    "\n",
    "# 바로 pivot을 시도하면 \"한 칸에 여러 값\"이라 에러가 날 수 있음\n",
    "# 해결: 먼저 GroupBy로 한 칸당 값 1개(합계)로 요약\n",
    "summary = df.groupby([\"ym\", \"day\"])[\"sales\"].sum().reset_index(name=\"total_sales\")\n",
    "\n",
    "# 그 다음 pivot\n",
    "report = summary.pivot(index=\"ym\", columns=\"day\", values=\"total_sales\")\n",
    "\n",
    "print(summary)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a58a866",
   "metadata": {},
   "source": [
    "2) 빈 칸(NaN)이 생기는 것\n",
    "\n",
    "피벗 표는 “월 × 요일”처럼 모든 칸이 항상 존재하지 않습니다.\n",
    "\n",
    "예를 들어 2026-02에는 화요일(Tue) 매출 데이터가 아예 없다면, 해당 칸은 비게 되고 NaN이 됩니다.\n",
    "\n",
    "이건 오류가 아니라 “그 조합의 데이터가 없다”는 뜻입니다.\n",
    "\n",
    "다만 리포트에서는 보통 아래 중 하나로 처리합니다.\n",
    "\n",
    "매출처럼 “없으면 0”이 자연스러우면 0으로 채움\n",
    "\n",
    "결측을 의미 있게 해석해야 하면 NaN을 유지\n",
    "\n",
    "간단 예제코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46d0ae6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "피벗 결과(빈 칸은 NaN)\n",
      "day        Mon   Tue\n",
      "ym                  \n",
      "2026-01  150.0  80.0\n",
      "2026-02  120.0   NaN\n",
      "\n",
      "리포트용(매출은 0으로 채움)\n",
      "day        Mon   Tue\n",
      "ym                  \n",
      "2026-01  150.0  80.0\n",
      "2026-02  120.0   0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "summary = pd.DataFrame([\n",
    "    {\"ym\": \"2026-01\", \"day\": \"Mon\", \"total_sales\": 150},\n",
    "    {\"ym\": \"2026-01\", \"day\": \"Tue\", \"total_sales\": 80},\n",
    "    {\"ym\": \"2026-02\", \"day\": \"Mon\", \"total_sales\": 120},\n",
    "    # 2026-02의 Tue 데이터는 일부러 없음 -> 피벗 후 NaN 발생\n",
    "])\n",
    "\n",
    "report = summary.pivot(index=\"ym\", columns=\"day\", values=\"total_sales\")\n",
    "\n",
    "print(\"피벗 결과(빈 칸은 NaN)\")\n",
    "print(report)\n",
    "\n",
    "report_filled = report.fillna(0)\n",
    "print(\"\\n리포트용(매출은 0으로 채움)\")\n",
    "print(report_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254e0cdd",
   "metadata": {},
   "source": [
    "정리\n",
    "\n",
    "NaN은 “값이 없다/기록이 없다”는 신호\n",
    "\n",
    "매출 리포트는 보통 fillna(0)을 많이 사용\n",
    "\n",
    "상황에 따라 NaN을 유지하는 것이 더 정확할 수도 있음(예: 측정 실패, 데이터 누락 분석)\n",
    "\n",
    "한 문장 결론\n",
    "\n",
    "*피벗은 “GroupBy로 만든 요약 결과를, 리포트에서 보기 좋은 표(행×열 구조)로 바꾸는 마지막 작업”입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94d8832",
   "metadata": {},
   "source": [
    "4. 문자열 처리 이론(실무형) 확장\n",
    "\n",
    "4-1. 왜 문자열 처리가 필수인가?\n",
    "\n",
    "실무 데이터에서 문자열은 거의 항상 “정리되지 않은 상태”로 들어옵니다.\n",
    "\n",
    "문제는 이게 보기만 지저분한 게 아니라, 분석 결과를 틀리게 만들거나 계산 자체를 못 하게 만든다는 점입니다.\n",
    "\n",
    "대표적인 상황 2가지\n",
    "\n",
    "1. 같은 값인데 다르게 저장됨(표기 흔들림)\n",
    "\n",
    "\" Latte \", \"latte\", \"LATTE\" 사람 눈에는 같은 메뉴지만, 컴퓨터는 다른 값으로 봅니다.\n",
    "\n",
    "결과: GroupBy를 하면 Latte가 여러 그룹으로 쪼개져서 집계가 깨집니다.\n",
    "\n",
    "2. 숫자가 문자열로 섞여 들어옴(단위/쉼표/통화 기호)\n",
    "\n",
    "- \"4,500원\", \"5000\", \"5,000원\" → 숫자처럼 보이지만 문자열이라 합계/평균 계산이 실패하거나 왜곡됩니다.\n",
    "\n",
    "문자열 정리를 안 하면 생기는 문제\n",
    "\n",
    "- 메뉴별 매출 TOP이 잘못 나옴(같은 메뉴가 여러 줄로 나뉨)\n",
    "\n",
    "- 가격 합계가 안 되거나(문자열이라), 일부만 변환돼 왜곡됨\n",
    "\n",
    "    - 필터 조건이 제대로 안 걸림(공백/대소문자 차이 때문에)\n",
    "\n",
    "핵심 정리\n",
    "\n",
    "문자열 처리는 “꾸미기”가 아니라 분석 가능한 값으로 통일하는 작업입니다.\n",
    "\n",
    "즉, “분석 전에 통일”이 목적입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a5c814",
   "metadata": {},
   "source": [
    "4-2. 초보자 기준 핵심 5가지 + 예시코드\n",
    "\n",
    "아래 코드는 카페 데이터를 예로 들어, 현업에서 가장 많이 쓰는 문자열 처리 패턴을 한 번에 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e69688e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본\n",
      "            menu   price           note\n",
      "0         Latte   4,500원     NEW member\n",
      "1          latte    5000     vip MEMBER\n",
      "2          LATTE  5,000원  Member coupon\n",
      "3      Americano   4500원          guest\n",
      "4  Vanilla Latte  5,800원     new_member\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {\"menu\": \" Latte \",        \"price\": \"4,500원\", \"note\": \"NEW member\"},\n",
    "    {\"menu\": \"latte\",          \"price\": \"5000\",     \"note\": \"vip MEMBER\"},\n",
    "    {\"menu\": \"LATTE\",          \"price\": \"5,000원\",  \"note\": \"Member coupon\"},\n",
    "    {\"menu\": \"Americano\",      \"price\": \"4500원\",   \"note\": \"guest\"},\n",
    "    {\"menu\": \"Vanilla Latte\",  \"price\": \"5,800원\",  \"note\": \"new_member\"},\n",
    "])\n",
    "\n",
    "print(\"원본\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1550397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "strip 적용\n",
      "            menu     menu_clean\n",
      "0         Latte           Latte\n",
      "1          latte          latte\n",
      "2          LATTE          LATTE\n",
      "3      Americano      Americano\n",
      "4  Vanilla Latte  Vanilla Latte\n"
     ]
    }
   ],
   "source": [
    "# 1) 공백 제거: strip\n",
    "# \n",
    "# 앞뒤 공백은 그룹화/필터링을 망치는 대표 원인입니다.\n",
    "\n",
    "df[\"menu_clean\"] = df[\"menu\"].str.strip() # _clean : 새로운 컬럼을 만들어 정제되었다고 표기! 항상 새로운 테이블 또는 파생 컬럼을 만들어 비교한다.\n",
    "print(\"\\nstrip 적용\")\n",
    "print(df[[\"menu\", \"menu_clean\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb788ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lower/title 적용\n",
      "      menu_clean     menu_lower     menu_title\n",
      "0          Latte          latte          Latte\n",
      "1          latte          latte          Latte\n",
      "2          LATTE          latte          Latte\n",
      "3      Americano      americano      Americano\n",
      "4  Vanilla Latte  vanilla latte  Vanilla Latte\n"
     ]
    }
   ],
   "source": [
    "# 2) 대소문자 통일: lower / title\n",
    "# \n",
    "# lower()는 비교/필터에 강함\n",
    "# \n",
    "# title()은 보기(리포트 출력)에 깔끔함\n",
    "\n",
    "df[\"menu_lower\"] = df[\"menu_clean\"].str.lower()\n",
    "df[\"menu_title\"] = df[\"menu_clean\"].str.title()\n",
    "\n",
    "print(\"\\nlower/title 적용\")\n",
    "print(df[[\"menu_clean\", \"menu_lower\", \"menu_title\"]])\n",
    "\n",
    "# 실무 팁\n",
    "# \n",
    "# - 내부 처리(정합성)는 lower()로 통일\n",
    "# \n",
    "# - 최종 출력(보기)은 title()로 정리(선택)\n",
    "# \n",
    "#     - 이 방식이 실수 줄이기 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c0a2e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "contains로 member 관련만 필터\n",
      "            note\n",
      "0     NEW member\n",
      "1     vip MEMBER\n",
      "2  Member coupon\n",
      "4     new_member\n"
     ]
    }
   ],
   "source": [
    "# 3) 포함 여부 필터: contains\n",
    "# \n",
    "# 특정 단어가 들어간 행만 뽑을 때 사용합니다.\n",
    "\n",
    "# note 컬럼에서 'member'가 포함된 행만 필터(대소문자 무시)\n",
    "member_df = df[df[\"note\"].str.contains(\"member\", case=False, na=False)] # case => 대소문자\n",
    "print(\"\\ncontains로 member 관련만 필터\")\n",
    "print(member_df[[\"note\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53757d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "replace + 숫자 변환\n",
      "    price  price_num\n",
      "0  4,500원       4500\n",
      "1    5000       5000\n",
      "2  5,000원       5000\n",
      "3   4500원       4500\n",
      "4  5,800원       5800\n"
     ]
    }
   ],
   "source": [
    "# 4) 치환: replace\n",
    "# \n",
    "# 가격에서 쉼표/원 제거 후 숫자로 바꾸는 전형적인 패턴입니다.\n",
    "\n",
    "df[\"price_num\"] = (\n",
    "    df[\"price\"]\n",
    "      .str.replace(\",\", \"\", regex=False)\n",
    "      .str.replace(\"원\", \"\", regex=False)\n",
    ")\n",
    "\n",
    "df[\"price_num\"] = pd.to_numeric(df[\"price_num\"], errors=\"coerce\")\n",
    "\n",
    "print(\"\\nreplace + 숫자 변환\")\n",
    "print(df[[\"price\", \"price_num\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "330fe321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "split 적용(첫 단어 추출)\n",
      "      menu_title menu_first_word\n",
      "0          Latte           Latte\n",
      "1          Latte           Latte\n",
      "2          Latte           Latte\n",
      "3      Americano       Americano\n",
      "4  Vanilla Latte         Vanilla\n"
     ]
    }
   ],
   "source": [
    "# 5) 분리: split\n",
    "# \n",
    "# 문자열을 나눠서 필요한 정보만 뽑을 때 사용합니다.\n",
    "# \n",
    "# 예: 메뉴명을 공백 기준으로 나누고 첫 단어만 추출\n",
    "\n",
    "df[\"menu_first_word\"] = df[\"menu_title\"].str.split().str[0]\n",
    "print(\"\\nsplit 적용(첫 단어 추출)\")\n",
    "print(df[[\"menu_title\", \"menu_first_word\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48e8c90",
   "metadata": {},
   "source": [
    "# 5. 시간 데이터 처리 이론(실무형)\n",
    "\n",
    "5-1. 왜 날짜 처리가 중요한가?\n",
    "\n",
    "리포트는 거의 항상 “시간축”이 들어갑니다.\n",
    "\n",
    "월별 매출, 주간 매출, 요일별 패턴, 시간대별 피크 같은 분석은 전부 “시간”이 기준이에요. pandas도 시간 데이터 처리를 위한 기능을 많이 제공합니다. \n",
    "\n",
    "문제는 날짜가 문자열(str)로 들어오면 아래가 자주 깨집니다.\n",
    "\n",
    "- 정렬이 이상해짐(문자열 정렬 문제)\n",
    "\n",
    "문자열은 “시간 순서”가 아니라 “글자 순서(사전순)”로 정렬될 수 있습니다.\n",
    "\n",
    "특히 dd/mm/yyyy 같은 형식은 시간 순서와 사전순이 잘 맞지 않아 더 자주 문제를 만듭니다. \n",
    "\n",
    "간단 예제코드: 문자열 정렬 vs datetime 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dab0457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     date_str  sales\n",
      "0  2026/01/02    100\n",
      "2  2026/01/03    150\n",
      "1  2026/01/10    200\n",
      "     date_str  sales       date\n",
      "0  2026/01/02    100 2026-01-02\n",
      "2  2026/01/03    150 2026-01-03\n",
      "1  2026/01/10    200 2026-01-10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"date_str\": [\"2026/01/02\", \"2026/01/10\", \"2026/01/03\"],\n",
    "    \"sales\": [100, 200, 150]\n",
    "})\n",
    "\n",
    "print(df.sort_values(\"date_str\"))  # 문자열 기준 정렬\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"date_str\"])\n",
    "print(df.sort_values(\"date\"))      # datetime 기준 정렬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44e1c75",
   "metadata": {},
   "source": [
    "기준 정렬\n",
    "\n",
    "1. 파생 피처를 못 만듦(월/요일/주차 등)\n",
    "\n",
    "“월별/요일별” 분석을 하려면 month, day_name 같은 파생 컬럼이 필요합니다.\n",
    "\n",
    "그런데 날짜가 문자열이면 .dt(datetime 전용 기능)를 쓸 수 없어서 파생 피처 생성이 막힙니다. \n",
    "\n",
    "2. 기간 필터링이 어려움\n",
    "\n",
    "“2026-01만 보기”, “특정 기간만 자르기” 같은 작업이 날짜 계산 기반이라,\n",
    "\n",
    "문자열 상태로는 실수(경계값, 포함/제외)가 늘어납니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c122c3",
   "metadata": {},
   "source": [
    "## 5-2. 핵심 개념: “datetime으로 바꾸고 파생 피처 만든다”\n",
    "\n",
    "초보자 기준으로는 이 한 줄이면 충분합니다.\n",
    "\n",
    "- 문자열 날짜 → pd.to_datetime()로 변환\n",
    "\n",
    "- .dt로 year/month/day_name 같은 파생 피처 생성\n",
    "\n",
    "- (리포트용) ym(연-월) 컬럼 만들어 GroupBy/Pivot에 활용\n",
    "\n",
    "pd.to_datetime()는 문자열/배열/Series 등을 pandas의 datetime 타입으로 바꿔주는 대표 함수입니다. \n",
    "\n",
    "간단 예제코드: datetime 변환 + 파생 피처 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06e06a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  sales  year  month  day_name       ym\n",
      "0 2026-01-01  10000  2026      1  Thursday  2026-01\n",
      "1 2026-01-03  15000  2026      1  Saturday  2026-01\n",
      "2 2026-02-01  20000  2026      2    Sunday  2026-02\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"date\": [\"2026-01-01\", \"2026-01-03\", \"2026-02-01\"],\n",
    "    \"sales\": [10000, 15000, 20000]\n",
    "})\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])  # 핵심 1) datetime 변환\n",
    "\n",
    "df[\"year\"] = df[\"date\"].dt.year\n",
    "df[\"month\"] = df[\"date\"].dt.month\n",
    "df[\"day_name\"] = df[\"date\"].dt.day_name()\n",
    "\n",
    "# 연-월(리포트에서 자주 쓰는 키): to_period('M') 활용\n",
    "df[\"ym\"] = df[\"date\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2021cf16",
   "metadata": {},
   "source": [
    "초보자용 요약\n",
    "\n",
    "- datetime 변환 = 시간 분석의 문 열기\n",
    "\n",
    "- 파생 피처(ym, day_name 등) = 월별/요일별 리포트의 재료\n",
    "\n",
    "- 이후 GroupBy/Pivot이 훨씬 쉬워집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8d205e",
   "metadata": {},
   "source": [
    "# 6. 데이터 결합(merge/join/concat)\n",
    "\n",
    "## 6-1. 결합은 왜 필요한가?\n",
    "\n",
    "원본 로그(주문 데이터)에는 보통 분석에 필요한 정보가 다 들어있지 않습니다.\n",
    "\n",
    "그래서 “다른 테이블의 정보를 옆으로 붙여서(확장해서)” 분석을 합니다.\n",
    "\n",
    "카페 예시\n",
    "\n",
    "- 주문 로그: date, menu, sales, customer_id 는 있는데\n",
    "\n",
    "- 메뉴 카테고리(커피/라떼/디저트)는 menu_map 같은 별도 표에 있음\n",
    "\n",
    "- 고객 도시/등급은 customers 표에 있음\n",
    "\n",
    "즉, 분석을 하려면\n",
    "\n",
    "- 주문 로그 + 메뉴 매핑표 + 고객 정보표를 결합해야 합니다.\n",
    "\n",
    "간단 예제코드(데이터 준비)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b45550b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id        date       menu  sales customer_id\n",
      "0         1  2026-01-01      Latte   5000         C01\n",
      "1         2  2026-01-01  Americano   4500         C02\n",
      "2         3  2026-01-02       Cake   6000         C03\n",
      "        menu category\n",
      "0      Latte   Coffee\n",
      "1  Americano   Coffee\n",
      "  customer_id    city   grade\n",
      "0         C01   Suwon     VIP\n",
      "1         C02  Yongin     NEW\n",
      "2         C03   Suwon  NORMAL\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "orders = pd.DataFrame([\n",
    "    {\"order_id\": 1, \"date\": \"2026-01-01\", \"menu\": \"Latte\",     \"sales\": 5000, \"customer_id\": \"C01\"},\n",
    "    {\"order_id\": 2, \"date\": \"2026-01-01\", \"menu\": \"Americano\", \"sales\": 4500, \"customer_id\": \"C02\"},\n",
    "    {\"order_id\": 3, \"date\": \"2026-01-02\", \"menu\": \"Cake\",      \"sales\": 6000, \"customer_id\": \"C03\"},\n",
    "])\n",
    "\n",
    "menu_map = pd.DataFrame([\n",
    "    {\"menu\": \"Latte\",     \"category\": \"Coffee\"},\n",
    "    {\"menu\": \"Americano\", \"category\": \"Coffee\"},\n",
    "    # Cake가 빠져있다고 가정(매핑 누락 사례)\n",
    "])\n",
    "\n",
    "customers = pd.DataFrame([\n",
    "    {\"customer_id\": \"C01\", \"city\": \"Suwon\", \"grade\": \"VIP\"},\n",
    "    {\"customer_id\": \"C02\", \"city\": \"Yongin\",\"grade\": \"NEW\"},\n",
    "    {\"customer_id\": \"C03\", \"city\": \"Suwon\", \"grade\": \"NORMAL\"},\n",
    "])\n",
    "\n",
    "print(orders)\n",
    "print(menu_map)\n",
    "print(customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469bc7a9",
   "metadata": {},
   "source": [
    "6-2. merge = “키로 붙이는 조인”\n",
    "\n",
    "merge는 SQL JOIN과 비슷하게 공통 키(key)로 옆으로 붙이는 기능입니다. pandas에서도 “database-style join”이라고 설명합니다. \n",
    "\n",
    "예: menu를 키로 menu_map(메뉴→카테고리)를 붙이면\n",
    "\n",
    "“메뉴별 매출”을 “카테고리별 매출” 같은 분석으로 확장할 수 있습니다.\n",
    "\n",
    "간단 예제코드(주문 + 메뉴카테고리 붙이기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8762e567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id        date       menu  sales customer_id category\n",
      "0         1  2026-01-01      Latte   5000         C01   Coffee\n",
      "1         2  2026-01-01  Americano   4500         C02   Coffee\n",
      "2         3  2026-01-02       Cake   6000         C03      NaN\n",
      "category\n",
      "Coffee    9500\n",
      "Name: sales, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "merged = orders.merge(menu_map, on=\"menu\", how=\"left\")  # 매핑표는 보통 left로 붙임\n",
    "print(merged)\n",
    "# 이제 category가 생겼으니 카테고리별 매출도 가능해집니다.\n",
    "\n",
    "cat_sales = merged.groupby(\"category\")[\"sales\"].sum()\n",
    "print(cat_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bb7907",
   "metadata": {},
   "source": [
    "6-3. how 옵션(초보자 필수 3종)\n",
    "\n",
    "how는 “어떤 기준으로 행을 남길지”를 정하는 옵션이고, pandas 문서에 각 동작이 SQL join과 유사하다고 정리되어 있습니다. \n",
    "\n",
    "1. left: 왼쪽(원본) 유지\n",
    "\n",
    "실무에서 “원본 로그는 유지하고, 매핑이 있으면 붙이고, 없으면 NaN으로 확인”할 때 가장 많이 씁니다. \n",
    "\n",
    "2. inner: 양쪽에 모두 있는 것만\n",
    "\n",
    "“매핑이 제대로 됐는지(정합성)” 확인할 때 유용합니다. \n",
    "\n",
    "3. outer: 전체 합치기(누락 탐색)\n",
    "\n",
    "“어느 쪽에만 있는 값이 있나?” 누락/신규 항목 탐색에 좋습니다. \n",
    "\n",
    "간단 예제코드(left / inner / outer 비교)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98bf83d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left\n",
      "    order_id        date       menu  sales customer_id category\n",
      "0         1  2026-01-01      Latte   5000         C01   Coffee\n",
      "1         2  2026-01-01  Americano   4500         C02   Coffee\n",
      "2         3  2026-01-02       Cake   6000         C03      NaN\n",
      "inner\n",
      "    order_id        date       menu  sales customer_id category\n",
      "0         1  2026-01-01      Latte   5000         C01   Coffee\n",
      "1         2  2026-01-01  Americano   4500         C02   Coffee\n",
      "outer\n",
      "    order_id        date       menu  sales customer_id category\n",
      "0         2  2026-01-01  Americano   4500         C02   Coffee\n",
      "1         3  2026-01-02       Cake   6000         C03      NaN\n",
      "2         1  2026-01-01      Latte   5000         C01   Coffee\n"
     ]
    }
   ],
   "source": [
    "left_join  = orders.merge(menu_map, on=\"menu\", how=\"left\")\n",
    "inner_join = orders.merge(menu_map, on=\"menu\", how=\"inner\")\n",
    "outer_join = orders.merge(menu_map, on=\"menu\", how=\"outer\")\n",
    "\n",
    "print(\"left\\n\", left_join)\n",
    "print(\"inner\\n\", inner_join)\n",
    "print(\"outer\\n\", outer_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595ed7ce",
   "metadata": {},
   "source": [
    "실무 팁(초보자에게 꼭)\n",
    "\n",
    "- 매핑표 붙일 때는 보통 left로 붙인 뒤,\n",
    "\n",
    "- category가 NaN인 행을 찾아서 “매핑 누락”을 수정합니다.\n",
    "\n",
    "간단 예제코드(매핑 누락 찾기: indicator 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76b221b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   menu  order_id\n",
      "2  Cake         3\n"
     ]
    }
   ],
   "source": [
    "check = orders.merge(menu_map, on=\"menu\", how=\"left\", indicator=True)\n",
    "missing = check[check[\"_merge\"] == \"left_only\"]  # 왼쪽에만 있음 = 매핑표에 없음\n",
    "print(missing[[\"menu\", \"order_id\"]])\n",
    "\n",
    "# - indicator=True는 병합 결과에 행 출처를 표시해 주는 옵션입니다. \n",
    "\n",
    "# - 참고로 DataFrame.join()은 기본이 index 기반 결합에 가깝고(기본적으로 인덱스로 조인), 기본 how='left'입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99dd91e",
   "metadata": {},
   "source": [
    "6-4. concat은 뭐가 다르냐?\n",
    "\n",
    "concat은 merge처럼 “키로 옆에 붙이기”가 아니라, 보통 위아래로 쌓아서(누적) 데이터 양을 늘릴 때 씁니다.\n",
    "\n",
    "pandas 공식 문서도 “특정 axis 방향으로 concatenate(연결)”한다고 설명합니다. \n",
    "\n",
    "느낌 정리\n",
    "\n",
    "- merge: 옆으로 붙이기(정보 확장)\n",
    "\n",
    "- concat: 위아래로 쌓기(데이터 누적)\n",
    "\n",
    "간단 예제코드(두 달의 주문 로그를 위아래로 누적)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df5a4252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id       ym  sales\n",
      "0         1  2026-01   5000\n",
      "1         2  2026-01   4500\n",
      "2         3  2026-02   6000\n"
     ]
    }
   ],
   "source": [
    "jan = pd.DataFrame([\n",
    "    {\"order_id\": 1, \"ym\": \"2026-01\", \"sales\": 5000},\n",
    "    {\"order_id\": 2, \"ym\": \"2026-01\", \"sales\": 4500},\n",
    "])\n",
    "\n",
    "feb = pd.DataFrame([\n",
    "    {\"order_id\": 3, \"ym\": \"2026-02\", \"sales\": 6000},\n",
    "])\n",
    "\n",
    "all_orders = pd.concat([jan, feb], ignore_index=True)  # 위아래로 쌓기\n",
    "print(all_orders)\n",
    "# (참고) concat은 axis=1로 “옆으로” 붙일 수도 있지만, 그 경우는 같은 인덱스 기준으로 나란히 놓는 성격이라 보통은 merge와 용도가 다릅니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9d8d16",
   "metadata": {},
   "source": [
    "7. apply vs map 이론(언제 뭘 쓰나) 확장 + 쉬운 예제코드\n",
    "\n",
    "7-1. map: “값 치환/매핑”에 특화(간단·빠름)\n",
    "\n",
    "map은 한 컬럼의 값들을 “딕셔너리/매핑표”로 바꿀 때 가장 깔끔합니다.\n",
    "\n",
    "즉, “A를 B로 바꿔라” 같은 1:1 치환 작업이면 map이 1순위예요.\n",
    "\n",
    "대표 사용처\n",
    "\n",
    "- 채널 코드 바꾸기: kiosk → 키오스크, app → 앱\n",
    "\n",
    "- 등급 코드 바꾸기: 1 → VIP, 2 → NORMAL 등\n",
    "\n",
    "- 메뉴/카테고리 매핑(간단 버전): Latte → Coffee\n",
    "\n",
    "간단 예제코드: channel 코드 치환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4aaa2510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  channel channel_name\n",
      "0   kiosk         키오스크\n",
      "1     app            앱\n",
      "2   kiosk         키오스크\n",
      "3     web            웹\n",
      "Empty DataFrame\n",
      "Columns: [channel, channel_name]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"channel\": [\"kiosk\", \"app\", \"kiosk\", \"web\"]\n",
    "})\n",
    "\n",
    "channel_map = {\n",
    "    \"kiosk\": \"키오스크\",\n",
    "    \"app\": \"앱\",\n",
    "    \"web\": \"웹\"\n",
    "}\n",
    "\n",
    "df[\"channel_name\"] = df[\"channel\"].map(channel_map)\n",
    "print(df)\n",
    "# 초보자 실수 포인트\n",
    "# \n",
    "# - 매핑표에 없는 값은 결과가 NaN이 됩니다.\n",
    "# \n",
    "# - 누락이 있을 수 있으니 확인하는 습관이 좋아요.\n",
    "# \n",
    "# 누락 확인 예시\n",
    "\n",
    "missing = df[df[\"channel_name\"].isna()]\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7201748",
   "metadata": {},
   "source": [
    "7-2. apply: “행 단위 규칙”이 필요할 때\n",
    "\n",
    "apply는 규칙(로직)을 직접 써야 할 때 씁니다.\n",
    "\n",
    "특히 이런 상황에서 유용합니다.\n",
    "\n",
    "- 숫자 구간에 따라 등급 분류: 매출 0이면 C, 1~9999면 B, 10000 이상이면 A\n",
    "\n",
    "- 여러 컬럼을 동시에 보고 판단: paid가 False면 무조건 \"FAIL\", True면 매출 구간으로 등급 등\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4f93a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sales grade\n",
      "0      0     C\n",
      "1   3000     B\n",
      "2  12000     A\n",
      "   sales   paid label\n",
      "0  12000   True     A\n",
      "1   5000   True     B\n",
      "2   8000  False  FAIL\n"
     ]
    }
   ],
   "source": [
    "# 간단 예제코드 1: 매출 구간 등급(단일 컬럼 기준)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"sales\": [0, 3000, 12000]})\n",
    "\n",
    "def grade_sales(x):\n",
    "    if x == 0:\n",
    "        return \"C\"\n",
    "    elif x < 10000:\n",
    "        return \"B\"\n",
    "    else:\n",
    "        return \"A\"\n",
    "\n",
    "df[\"grade\"] = df[\"sales\"].apply(grade_sales)\n",
    "print(df)\n",
    "# 간단 예제코드 2: 여러 컬럼을 보고 판단(행 단위)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {\"sales\": 12000, \"paid\": True},\n",
    "    {\"sales\": 5000,  \"paid\": True},\n",
    "    {\"sales\": 8000,  \"paid\": False},\n",
    "])\n",
    "\n",
    "def final_label(row):\n",
    "    if row[\"paid\"] is False:\n",
    "        return \"FAIL\"\n",
    "    if row[\"sales\"] >= 10000:\n",
    "        return \"A\"\n",
    "    return \"B\"\n",
    "\n",
    "df[\"label\"] = df.apply(final_label, axis=1)  # axis=1: 행 기준\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec83290",
   "metadata": {},
   "source": [
    "7-3. 초보자에게 꼭 알려야 할 점: apply는 편하지만 느릴 수 있음\n",
    "\n",
    "apply는 “파이썬 함수로 한 행씩 처리”하는 경우가 많아서 데이터가 커지면 느려질 수 있습니다.\n",
    "\n",
    "그래서 가능하면 아래처럼 **벡터화(조건식)**로 처리하는 습관이 좋아요.\n",
    "\n",
    "apply 대신 벡터화로 등급 만들기(빠르고 깔끔)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05610870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sales grade_vec\n",
      "0      0         C\n",
      "1   3000         B\n",
      "2  12000         A\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"sales\": [0, 3000, 12000]})\n",
    "\n",
    "df[\"grade_vec\"] = \"B\"\n",
    "df.loc[df[\"sales\"] == 0, \"grade_vec\"] = \"C\"\n",
    "df.loc[df[\"sales\"] >= 10000, \"grade_vec\"] = \"A\"\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a2b472",
   "metadata": {},
   "source": [
    "한 줄 결론\n",
    "\n",
    "map = 한 컬럼 값들을 딕셔너리로 치환할 때(가볍고 빠름)\n",
    "\n",
    "apply = 규칙이 필요하거나 여러 컬럼을 같이 보고 판단해야 할 때(편하지만 커지면 느릴 수 있음)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed7c5f2",
   "metadata": {},
   "source": [
    "8. 오늘 수업을 한 문장으로 정리\n",
    "\n",
    "“원본 로그를 문자열/날짜 정리로 계산 가능하게 만들고, GroupBy로 요약하고, Merge로 정보 확장해서, 리포트용 표(요약테이블)를 만든다.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922ad1ce",
   "metadata": {},
   "source": [
    "9. 초보자용 퀴즈(이론 체크, 5문항)\n",
    "\n",
    "GroupBy는 왜 필요한가? “원본 로그”와 비교해서 설명해보세요.\n",
    "\n",
    "paid_rate = mean(paid)가 “비율”이 되는 이유는?\n",
    "\n",
    "MultiIndex가 불편한 이유와 해결 방법 1가지는?\n",
    "\n",
    "merge의 left와 inner의 차이를 “매핑 누락 찾기” 관점에서 설명해보세요.\n",
    "\n",
    "map과 apply는 언제 각각 쓰는가? 예시 1개씩 들어보세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
